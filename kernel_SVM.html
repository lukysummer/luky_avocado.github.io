<DOCTYPE! html>
<html>
<head>
	<link rel = "stylesheet" href = "DS_style.css">
	<script src = "js/main.js"></script>
</head>

<body style="margin: 0;">
	<style type="text/css"></style>
	
	<div id = "ml_page">
		<div id = 'title'>
			<p>Ｓｕｐｐｏｒｔ　Ｖｅｃｔｏｒ　Ｍａｃｈｉｎｅ　ｗ／　Ｋｅｒｎｅｌｓ<br></p>
		</div>
		<br>
		<div id="data2">
			<p>ＲＡＷ　ＤＡＴＡ</p>
			<img src = 'data_logiR.png' border='3'></img>
		</div>
		<div id = 'body2'>
			<br><br><br>❀ Ｓｕｐｐｏｒｔ　Ｖｅｃｔｏｒ　Ｍａｃｈｉｎｅ　ｗ／　Ｋｅｒｎｅｌｓ　ｆｏｒ　Ｂｉｎａｒｙ　Ｃｌａｓｓｉｆｉｃａｔｉｏｎ： <br><br><span id='scen'>
			- SVM tries to minimize the margin (distance) between the decision boundary and data points closest to the boundary.<br></span><span id='scen'>
			- A kernel projects the datapoints into higher dimensions to make it easier to separate the two classes.<br></span><span id='scen'>
			- parameters: <br></span><span id='scen'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1) kernel: Linear, Gaussian RBF (radial)<br></span><span id='scen'>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2) C: penalty parameteron wrong classification<br></span><span id='scen'>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If small- prioritizes the original SVM objective of maximizing the margin over correct classification <br></span><span id='scen'>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If large- big penalty on wrong classification- prioritizes correct classification over maximizing the margin<br></span><span id='scen'>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			(3) gamma: inversely related to the radial area of the decision boundary (bigger gamma = smaller radius of the radial decision boundary)</span>
			
			<br><br><br>❀ Ｂｅｓｔ　Ｔｕｔｏｒｉａｌｓ　ｏｎ　Ｓｕｐｐｏｒｔ　Ｖｅｃｔｏｒ　Ｍａｃｈｉｎｅ： <br><br>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a id=smallest href = "https://www.youtube.com/watch?v=_PwhiWxHK8" target="_blank">https://www.youtube.com/watch?v=_PwhiWxHK8</a>
			<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a id=smallest href = "http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank">http://cs229.stanford.edu/notes/cs229-notes3.pdf</a>
			
			<br><br><br>❀ Ｓｃｅｎａｒｉｏ： <br><br><span id='scen'>You are given a dataset 
			containing info of 400 website users with each user's age, salary, and whether or not she/he purchased the car.
			By analyzing this data, you are asked to predict if a new user with known age and salary will likely to purchase the car or not. </span>
			
			<br><br><br>❀ Ｄａｔａ　Ｐｒｅｐｒｏｃｅｓｓｉｎｇ：　<span id='scen'>
			<br><br>&nbsp;<b>Feature Scaling</b> was performed on both x & y features. It removed the mean 
			of the features and scaled the entries according to the variance of each entry compared to the mean.</span>
			
			<br><br><br>❀ Ｐｙｔｈｏｎ　Ｃｌａｓｓｅｓ　Ｕｓｅｄ： <br> <span id=classes>			
			<br>&nbsp;✣ (from sklearn.svm) <b>SVC</b> (C = 1, gamma = 0.5)
			<br>&nbsp;✣ (from sklearn.preprocessing) <b>StandardScaler</b></span>
			
			<br><br><br>❀ Ｒ　Ｐａｃｋａｇｅｓ／Ｃｌａｓｓｅｓ　Ｕｓｅｄ： <br> <span id=classes>
			<br>&nbsp;✣ <b>e1071</b>
			<br>&nbsp;✣ <b>svm</b></span>
			
			<br><br><br>❀ Ｉｍｐｌｅｍｅｎｔａｔｉｏｎ　ｉｎ　Ｐｙｔｈｏｎ　＆　Ｒ： <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<a id=smallest href = "https://github.com/lukysummer/Support-Vector-Machine-with-Kernels" target="_blank">https://github.com/lukysummer/Support-Vector-Machine-with-Kernels</a>
			
			<br><br><br>❀ Ａｃｃｕｒａｃｙ： <br><br>
			<table style="width:100%">
			  <tr>
				<td>kernel</td>
				<td>Training Accuracy</td>
				<td>Test Accuracy</td>
			  </tr>
			  <tr>
				<td><b>Linear</b></td>
				<td><b>0.8233333333333334</b></td>
				<td><b>0.90</b></td>
			  </tr>
			  <tr>
				<td><b>Gaussian RBF</b></td>
				<td><b>0.9033333333333333</b></td>
				<td><b>0.93</td>
		      </tr>
			</table>
			
			<br><br><br>❀ ＲＥＳＵＬＴＳ：　<br><br> <img src='lin_train.png'></img>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<img src='lin_test.png'></img>
			<br><br><span id='scen'>The two graphs above show the scatter plots of the raw training points (left graph) & raw test points (right graph): 
			red dots for Not Purchased (0) & blue dots for Purchased (1), along with the <b>linear decision boundary</b> generated by fitting 
			<b>SVM with Linear Kernel</b> to the training set. The model predicts that any new user with age & salary combination within the pink area will likely NOT 
			purchase the car, while one within the blue area will likely purchase the car. </span>
			
			<br><br><br><br> <img src='rbf_train.png'></img>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<img src='rbf_test.png'></img>
			<br><br><span id='scen'>The two graphs above show the scatter plots of the raw training points (left graph) & raw test points (right graph): 
			red dots for Not Purchased (0) & blue dots for Purchased (1), along with the <b>non-linear decision boundary</b> generated by fitting 
			<b>SVM with Gaussian RBF Kernel</b> to the training set. This decision boundary represents the dataset much better than the linear boundary,
			and thus resulting in higher training and test accuracies. However, one dangerous aspect is that due to the radial decision boundary, there is 
			a small blue region at the bottom left of the graphs. This means that the model will predict that users who are younger than 5 years old with 
			an income of less than $5000 will purchase the car. This could be solved by a bigger dataset including datapoints within the bottom left region, 
			ad tuning gamma parameter.
			</span><br><br><br><br>
		</div>
	</div>
</body>
</html>
