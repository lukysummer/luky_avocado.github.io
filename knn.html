<DOCTYPE! html>
<html>
<head>
	<link rel = "stylesheet" href = "DS_style.css">
	<script src = "js/main.js"></script>
</head>

<body style="margin: 0;">
	<style type="text/css"></style>
	
	<div id = "ml_page">
		<div id = 'title'>
			<p>Ｋ－Ｎｅａｒｅｓｔ　Ｎｅｉｇｈｂｏｒｓ　（Ｋ－ＮＮ）<br></p>
		</div>
		<br>
		<div id="data2">
			<p>ＲＡＷ　ＤＡＴＡ</p>
			<img src = 'data_logiR.png' border='3'></img>
		</div>
		<div id = 'body2'>
			<br><br><br>❀ Ｎｏｎ－Ｌｉｎｅａｒ　Ｃｌａｓｓｉｆｉｅｒ　ｗ／　Ｋ－ＮＮ：<br><br>
			<span id='scen'>1. Choose k (odd number): # of nearest neighbour data points to consider during training.<br></span>
			<span id='scen'>2. For each training point, select k nearest points. <br></span>
			<span id='scen'>3. Return the majority class of the k nearest points. </span>

			<br><br><br>❀ Ｓｃｅｎａｒｉｏ： <br><br><span id='scen'>You are given a dataset 
			containing info of 400 website users with each user's age, salary, and whether or not she/he purchased the car.
			By analyzing this data, you are asked to predict if a new user with known age and salary will likely to purchase the car or not. </span>
			
			<br><br><br>❀ Ｐｙｔｈｏｎ　Ｃｌａｓｓｅｓ　Ｕｓｅｄ： <br> <span id=classes>
			<br>&nbsp;✣ (from sklearn.neighbors) <b>KNeighborsClassifier</b>
			<br>&nbsp;✣ (from sklearn.preprocessing) <b>StandardScaler</b>
			<br>&nbsp;✣ (from sklearn.model_selection) <b>train_test_split</b>
			<br>&nbsp;✣ (from matplotlib.colors) <b>ListedColormap</b></span>
			
			<br><br><br>❀ Ｒ　Ｐａｃｋａｇｅｓ／Ｃｌａｓｓｅｓ　Ｕｓｅｄ： <br> <span id=classes>
			<br>&nbsp;✣ <b>class</b>
			<br>&nbsp;✣ <b>knn</b>
			<br>&nbsp;✣ <b>caTools</b></span>
			
			<br><br><br>❀ Ｉｍｐｌｅｍｅｎｔａｔｉｏｎ　ｉｎ　Ｐｙｔｈｏｎ　＆　Ｒ： <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<span id='run'> <b>*Try running the Python code & insert the new user's age and salary to see if she/he will purchase the car!*</b></span><br><br>
			<a id=smallest href = "https://github.com/lukysummer/k-Nearest-Neighbours" target="_blank">https://github.com/lukysummer/k-Nearest-Neighbours</a>
			
			<br><br><br>❀ Ａｃｃｕｒａｃｙ： 
			<br><br> <img src='accuracy_ plot.png'></img>
			<br><br><span id='scen'>The above plot shows the training & test accuracies with varying k from 1 to 100. It can be observed that the
			training accuracy is 100% at k=1, then drops right after with a decreasing trend. On the other hand, test accuracy is low (0.88) at 
			k=1, then goes up shortly after, stays high (~0.93) until around k=40, and starts decreasing for larger k values. The observation at
			k=1 can be explained by overfitting. <b>Optimal value of k</b> with highest training/test accuracy combination is found out to be <b>5</b> (with 
			<b>Training Accuracy = 0.9166666666666, Test Accuracy = 0.93</b>).</span>
			
			<br><br><br>❀ ＲＥＳＵＬＴＳ：　<br><br> <img src='5nn_train.png'></img>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<img src='5nn_test.png'></img>
			<br><br><span id='scen'>The two graphs above show the scatter plots of the raw training points (left graph) & raw test points (right graph): 
			red dots for Not Purchased (0) & blue dots for Purchased (1), along with the <b>non-linear decision boundary</b> generated by fitting 
			<b>5-NN</b> to the training set. The model predicts that any new user with age & salary combination within the pink area will likely NOT 
			purchase the car, while one within the blue area will likely purchase the car. </span>
			
			<br><br><br><br> <img src='1nn_train.png'></img>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<img src='1nn_test.png'></img>
			<br><br><span id='scen'>The two graphs above show the scatter plots of the raw training points (left graph) & raw test points (right graph): 
			red dots for Not Purchased (0) & blue dots for Purchased (1), along with the <b>non-linear decision boundary</b> generated by fitting 
			<b>1-NN</b> to the training set. The traces of overfitting is evident in the graphs, as every single red training points including ones that
			are far from majority of the red points are considered for the decision boundary. This leads to incorrect prediction for the testing set that
			does not contain such outliers. Such is well-prevented in the 5-NN plots.</span>
			</span><br><br><br><br>
		</div>
	</div>
</body>
</html>
